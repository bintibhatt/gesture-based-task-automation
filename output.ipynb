{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, lite\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import datetime\n",
    "from operator import index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands  # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utilities\n",
    "\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    # COLOR CONVERSION BGR 2 RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw left hand connections\n",
    "    if not results.multi_hand_landmarks:\n",
    "        return\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(111, 22, 76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(\n",
    "                                      color=(121, 44, 250), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    if not results.multi_hand_landmarks:\n",
    "        return\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        # Draw left hand connections\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.landmark[point].x, res.landmark[point].y, res.landmark[point].z]\n",
    "                  for point in mp_hands.HandLandmark for res in results.multi_hand_landmarks], dtype=float).flatten() if results.multi_hand_landmarks else np.zeros(21*3*2)\n",
    "    if lh.shape[0] == 63:\n",
    "        rh = np.array([[res.landmark[point].x, res.landmark[point].y, res.landmark[point].z]\n",
    "                      for point in mp_hands.HandLandmark for res in results.multi_hand_landmarks], dtype=float).flatten() if results.multi_hand_landmarks else np.zeros(21*3)\n",
    "        return np.concatenate([lh, rh])\n",
    "    return np.concatenate([lh])\n",
    "\n",
    "\n",
    "colors = [\n",
    "    (255, 0, 0),   # Red\n",
    "    (0, 255, 0),   # Green\n",
    "    (0, 0, 255),   # Blue\n",
    "    (255, 255, 0),  # Yellow\n",
    "    (255, 0, 255),  # Magenta\n",
    "    (0, 255, 255),  # Cyan\n",
    "    (128, 128, 128)  # Gray\n",
    "]\n",
    "\n",
    "\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = cv2.resize(input_frame, (1000, 800))\n",
    "    cv2.rectangle(output_frame, (0, 0), (800, 60), (255, 255, 255), -1)\n",
    "    cv2.putText(output_frame, 'Gesture Detection', (10, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (50, 100 + num * 50),\n",
    "                      (50 + int(prob * 700), 130 + num * 50), colors[num], -1)\n",
    "        cv2.putText(output_frame, f'{actions[num]}: {prob:.2f}', (\n",
    "            60, 125 + num * 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions that we try to detect\n",
    "actions = np.array(['thumbsup', 'thumbsdown', 'peace', 'palm', 'fist'])\n",
    "\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"action.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 82\u001b[0m\n\u001b[0;32m     78\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyWindow()\n\u001b[0;32m     80\u001b[0m \u001b[39mif\u001b[39;00m word \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mthumbsdown\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     81\u001b[0m     \u001b[39m# Delete the photo if the gesture is thumbs up\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename):\n\u001b[0;32m     83\u001b[0m         os\u001b[39m.\u001b[39mremove(filename)\n\u001b[0;32m     84\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPhoto deleted:\u001b[39m\u001b[39m\"\u001b[39m, filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "# final code\n",
    "\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.9\n",
    "# timestamp = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "# counter = 1\n",
    "\n",
    "try:\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        start_time = time.time()\n",
    "        while cap.isOpened():\n",
    "\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, hands)\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "\n",
    "            # Prediction logic\n",
    "            keypoints = extract_keypoints(results)\n",
    "            sequence.append(keypoints)\n",
    "            sequence = sequence[-30:]\n",
    "\n",
    "            if len(sequence) == 30:\n",
    "                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                predictions.append(np.argmax(res))\n",
    "\n",
    "                # Viz logic\n",
    "                if np.unique(predictions[-10:])[0] == np.argmax(res):\n",
    "                    if res[np.argmax(res)] > threshold:\n",
    "\n",
    "                        word = \"\"\n",
    "                        if len(sentence) > 0:\n",
    "                            if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "                                word = actions[np.argmax(res)]\n",
    "                        else:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                            word = actions[np.argmax(res)]\n",
    "\n",
    "                        if word == \"thumbsup\":\n",
    "                            # Save the photo with a unique filename\n",
    "                            delay = 5000\n",
    "                            # filename = \"photo_{}.png\".format((timestamp)_(counter))\n",
    "                            filename = \"photo_{}.png\".format(counter)\n",
    "                            cv2.imwrite(filename, frame)\n",
    "                            print(\"Photo saved as\", filename)\n",
    "                            # Break out of the loop after taking one photo\n",
    "                            delay = 10000\n",
    "\n",
    "                        if word == \"palm\":\n",
    "                            # Save the photo with a unique filename\n",
    "                            delay = 5000\n",
    "                            cv2.imshow(filename, frame)\n",
    "                            # Break out of the loop after taking one photo\n",
    "                            delay = 10000\n",
    "                            cv2.destroyWindow()\n",
    "\n",
    "                        if word == \"thumbsdown\":\n",
    "                            # Delete the photo if the gesture is thumbs up\n",
    "                            if os.path.exists(filename):\n",
    "                                os.remove(filename)\n",
    "                                print(\"Photo deleted:\", filename)\n",
    "                            else:\n",
    "                                print(\"File does not exist:\", filename)\n",
    "\n",
    "                if len(sentence) > 1:\n",
    "                    sentence = sentence[-1:]\n",
    "\n",
    "                # Viz probabilities\n",
    "                image = prob_viz(res, actions, image, colors)\n",
    "\n",
    "            # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "            # Break gracefully\n",
    "            if cv2.waitKey(10) & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
